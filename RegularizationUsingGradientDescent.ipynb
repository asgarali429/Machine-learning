{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVGvyJ1EQg210zkqtJpW8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asgarali429/Machine-learning/blob/main/RegularizationUsingGradientDescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "YXXJ0Zc6qVDt"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "5qXDoG9App9T"
      },
      "outputs": [],
      "source": [
        "class gdregressor:\n",
        "\n",
        "  def __init__(self,epochs,learning_rate,alpha,batch_size):\n",
        "    self.m = None\n",
        "    self.b = None\n",
        "    self.epochs = epochs\n",
        "    self.lr = learning_rate\n",
        "    self.alpha = alpha\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def fit(self,xtrain,ytrain):\n",
        "    self.m = np.ones(xtrain.shape[1])\n",
        "    self.b = 0\n",
        "\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      for j in range(xtrain.shape[0]//self.batch_size):\n",
        "        idx = random.sample(range(xtrain.shape[0]),self.batch_size)\n",
        "        yhat = np.dot(xtrain[idx],self.m) + self.b\n",
        "        b_der = -2 * np.mean(ytrain[idx] - yhat)\n",
        "        self.b = self.b - (self.lr*b_der)\n",
        "\n",
        "        m_der = (-2 * np.dot((ytrain[idx]-yhat),xtrain[idx])) + 2 * self.alpha * self.m\n",
        "\n",
        "        self.m = self.m - (self.lr*m_der)\n",
        "\n",
        "\n",
        "    print(self.b,self.m)\n",
        "    print(self.m.shape)\n",
        "\n",
        "  def predict(self,xtest):\n",
        "\n",
        "     return np.dot(xtest,self.m) + self.b\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "lccMAoR7xtlo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X,y = load_diabetes(return_X_y=True)\n"
      ],
      "metadata": {
        "id": "o0rXGQ8iydjl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_yQ8ixLuyjIx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)"
      ],
      "metadata": {
        "id": "7YR1iPRKylyf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import SGDRegressor"
      ],
      "metadata": {
        "id": "IrHsH9kSyoLQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = SGDRegressor(penalty='l2',max_iter=500,eta0=0.1,learning_rate='constant',alpha=0.001)"
      ],
      "metadata": {
        "id": "CVDlOtTQyqo4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = reg.predict(X_test)\n",
        "print(\"R2 score\",r2_score(y_test,y_pred))\n",
        "print(reg.coef_)\n",
        "print(reg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow-KGw_Byzsc",
        "outputId": "d94b37a9-7a2f-4afc-be6e-cbcc13ad1df4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score 0.4600715996815121\n",
            "[  46.24513931 -162.37122121  368.24025678  272.37168023  -11.51199363\n",
            "  -62.25303541 -171.75943251  137.41898869  332.50491698   96.79356179]\n",
            "[152.92322421]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdr = gdregressor(70,0.01,0.001,10)"
      ],
      "metadata": {
        "id": "iPCVyB3ky0Mb"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdr.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtBZ8gChzFuG",
        "outputId": "43757745-df73-44f8-cede-c13b0049c9fe"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151.34214349742416 [  60.65830945 -137.47665255  382.75888921  283.81270002    2.98972954\n",
            "  -57.08305131 -173.72336992  143.92496506  342.72193457  127.90488533]\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=gdr.predict(X_test)"
      ],
      "metadata": {
        "id": "Hx58qv0uzIW3"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD3D90Bo1RJh",
        "outputId": "84e73f6b-8eda-4516-8f51-aee4d1ac76f5"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4604723739777792"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How are coefficients affected?\n",
        "It decrease the weight of coefficient near zero but it never be zero.\n",
        "\n",
        "Higher Coefficients are affected more?\n",
        "Yes,higher coefficents are more effected by regularization\n",
        "\n",
        "\n",
        "Impact on Bias and Variance\n",
        "when we increase the alpha value there will be high chance of biasness\n",
        "when we decrease the alpha value there will be high chance of variance\n",
        "\n",
        "effect of regularization on loss function\n",
        "the loss function to include a penalty term that discourages overly complex models."
      ],
      "metadata": {
        "id": "XfYKddTM-KhM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wp_j1lCn9pfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}